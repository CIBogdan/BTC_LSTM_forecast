{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4siQDRDLZfp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# -------------------------\n",
        "# Config / Setări\n",
        "# -------------------------\n",
        "SALVEAZA_CSV = True\n",
        "RANDOM_STATE = 42\n",
        "ANI = 5  # fereastra istorică pentru macro\n",
        "\n",
        "# -------------------------\n",
        "# Utilitare\n",
        "# -------------------------\n",
        "def asigura_folder(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# 1. Descărcare date\n",
        "# -------------------------\n",
        "def descarca_btc_si_macro(ani=ANI):\n",
        "    sfarsit = datetime.today()\n",
        "    start = sfarsit - timedelta(days=ani*365)\n",
        "\n",
        "    tickere = {\n",
        "        'BTC-USD': 'Bitcoin',\n",
        "        '^GSPC': 'S&P 500',\n",
        "        'GC=F': 'Aur',\n",
        "        'CL=F': 'WTI',\n",
        "        '^VIX': 'VIX',\n",
        "        'DX-Y.NYB': 'DXY',\n",
        "        'TIPS': 'TIPS'\n",
        "    }\n",
        "\n",
        "    print(f\"Se descarcă {len(tickere)} tickere din {start.date()} până în {sfarsit.date()}...\")\n",
        "    raw = yf.download(list(tickere.keys()), start=start, end=sfarsit, interval=\"1d\", progress=False)\n",
        "\n",
        "    # preferăm 'Adj Close' dacă există\n",
        "    if 'Adj Close' in raw.columns:\n",
        "        df_raw = raw['Adj Close'].copy()\n",
        "    elif 'Close' in raw.columns:\n",
        "        df_raw = raw['Close'].copy()\n",
        "    else:\n",
        "        raise ValueError('Nu există coloana Close sau Adj Close în datele descărcate')\n",
        "\n",
        "    df_raw.columns = list(tickere.values())\n",
        "    df_raw = df_raw.sort_index()\n",
        "    return df_raw\n",
        "\n",
        "# -------------------------\n",
        "# 2. Preprocesare & curățare\n",
        "# -------------------------\n",
        "def preproceseaza(df):\n",
        "    df = df.copy()\n",
        "    macro_cols = [c for c in df.columns if c != 'Bitcoin']\n",
        "\n",
        "    df = df.dropna(how='all')            # eliminăm rânduri complet goale\n",
        "    df[macro_cols] = df[macro_cols].ffill()  # propagăm valorile macro\n",
        "    df = df.dropna(subset=['Bitcoin'])   # eliminăm rânduri fără target\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# 3. Eliminare valori aberante (IQR)\n",
        "# -------------------------\n",
        "def elimina_outlieri_iqr(df, coloane_numerice=None):\n",
        "    df = df.copy()\n",
        "    if coloane_numerice is None:\n",
        "        coloane_numerice = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaled = pd.DataFrame(scaler.fit_transform(df[coloane_numerice]), index=df.index, columns=coloane_numerice)\n",
        "\n",
        "    masc_aberante = pd.Series(False, index=scaled.index)\n",
        "    for c in coloane_numerice:\n",
        "        Q1 = scaled[c].quantile(0.25)\n",
        "        Q3 = scaled[c].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        masc_aberante |= (scaled[c] < Q1 - 1.5*IQR) | (scaled[c] > Q3 + 1.5*IQR)\n",
        "\n",
        "    df_curat = df.loc[~masc_aberante].copy()\n",
        "    return df_curat, masc_aberante\n",
        "\n",
        "# -------------------------\n",
        "# 4. Feature engineering\n",
        "# -------------------------\n",
        "def adauga_caracteristici_btc(df):\n",
        "    df = df.copy()\n",
        "    df['BTC_lag1'] = df['Bitcoin'].shift(1)\n",
        "    df['BTC_lag2'] = df['Bitcoin'].shift(2)\n",
        "    df['BTC_ma7'] = df['Bitcoin'].rolling(7).mean()\n",
        "    df['BTC_ma14'] = df['Bitcoin'].rolling(14).mean()\n",
        "    df['BTC_diff1'] = df['Bitcoin'].diff(1)\n",
        "    df['BTC_pct_change'] = df['Bitcoin'].pct_change(1)\n",
        "    df['BTC_vol_3'] = df['BTC_diff1'].rolling(3).std()\n",
        "    df['BTC_vol_7'] = df['BTC_diff1'].rolling(7).std()\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# 5. Split train/test\n",
        "# -------------------------\n",
        "def imparte_train_test(X, y, test_size=0.2, shuffle=False):\n",
        "    return train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "\n",
        "# -------------------------\n",
        "# 6. Evaluare modele clasice\n",
        "# -------------------------\n",
        "def evalueaza_modele_clasice(splituri):\n",
        "    modele = {\n",
        "        'LinearRegression': LinearRegression(),\n",
        "        'Lasso': Lasso(alpha=0.01),\n",
        "        'RandomForest': RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE),\n",
        "        'XGBoost': XGBRegressor(n_estimators=200, random_state=RANDOM_STATE, eval_metric='rmse'),\n",
        "        'SVR': SVR(),\n",
        "        'KNN': KNeighborsRegressor(n_neighbors=5)\n",
        "    }\n",
        "\n",
        "    rezultate = []\n",
        "    for nume_set, split in splituri.items():\n",
        "        X_train, X_test = split['X_train'], split['X_test']\n",
        "        y_train, y_test = split['y_train'], split['y_test']\n",
        "        print(f\"\\n=== Set de date: {nume_set} ===\")\n",
        "        for nume, model in modele.items():\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rezultate.append({'Set': nume_set, 'Model': nume, 'R2': r2, 'MSE': mse})\n",
        "            print(f\"{nume}: R2={r2:.4f}, MSE={mse:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(rezultate)\n",
        "\n",
        "# -------------------------\n",
        "# 7. Multi-target\n",
        "# -------------------------\n",
        "def analiza_multi_target(df, coloane_feat, coloane_target):\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    scalerX = MinMaxScaler()\n",
        "    scalerY = MinMaxScaler()\n",
        "\n",
        "    rezumat = []\n",
        "    fig, axes = plt.subplots(len(coloane_target), 3, figsize=(18, 4*len(coloane_target)))\n",
        "    axes = axes.reshape(len(coloane_target), 3)\n",
        "\n",
        "    for i, target in enumerate(coloane_target):\n",
        "        X = df[coloane_feat].values\n",
        "        y = df[target].values\n",
        "        Xs = scalerX.fit_transform(X)\n",
        "        ys = scalerY.fit_transform(y.reshape(-1,1)).ravel()\n",
        "\n",
        "        train_idx, test_idx = list(tscv.split(Xs))[-1]\n",
        "        X_train, X_test = Xs[train_idx], Xs[test_idx]\n",
        "        y_train_s, y_test_s = ys[train_idx], ys[test_idx]\n",
        "        y_test = y[test_idx]\n",
        "\n",
        "        model = RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE)\n",
        "        model.fit(X_train, y_train_s)\n",
        "        y_pred_s = model.predict(X_test)\n",
        "        y_pred = scalerY.inverse_transform(y_pred_s.reshape(-1,1)).ravel()\n",
        "\n",
        "        # plot linie\n",
        "        ax_line = axes[i,0]\n",
        "        ax_line.plot(df.index[test_idx], y_test, label='Real')\n",
        "        ax_line.plot(df.index[test_idx], y_pred, label='Pred', linestyle='--')\n",
        "        ax_line.set_title(f\"{target} - Serie temporală\")\n",
        "        ax_line.legend(); ax_line.grid(True)\n",
        "\n",
        "        # scatter + Pearson\n",
        "        ax_sc = axes[i,1]\n",
        "        ax_sc.scatter(y_test, y_pred, alpha=0.6)\n",
        "        mmin, mmax = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
        "        ax_sc.plot([mmin,mmax],[mmin,mmax],'r--')\n",
        "        r = np.corrcoef(y_test, y_pred)[0,1]\n",
        "        ax_sc.set_title(f\"{target} - Scatter (Pearson={r:.3f})\")\n",
        "\n",
        "        # cumsum\n",
        "        ax_cs = axes[i,2]\n",
        "        c_r = np.cumsum(y_test)\n",
        "        c_p = np.cumsum(y_pred)\n",
        "        ax_cs.plot(df.index[test_idx], c_r, label='Cumsum Real')\n",
        "        ax_cs.plot(df.index[test_idx], c_p, label='Cumsum Pred', linestyle='--')\n",
        "        r_cs = np.corrcoef(c_r, c_p)[0,1]\n",
        "        acc_sign = np.mean(np.sign(y_test[1:]) == np.sign(y_pred[1:]))\n",
        "        ax_cs.set_title(f\"{target} - Cumsum (Pearson={r_cs:.3f}, Acc_sign={acc_sign:.3f})\")\n",
        "        ax_cs.legend(); ax_cs.grid(True)\n",
        "\n",
        "        rezumat.append({'Target': target, 'Pearson': r, 'Pearson_cumsum': r_cs, 'Acc_sign': acc_sign})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return pd.DataFrame(rezumat)\n",
        "\n",
        "# -------------------------\n",
        "# 8. LSTM univariabil\n",
        "# -------------------------\n",
        "def creeaza_secvente_univariabile(serie, lookback=30):\n",
        "    X, y = [], []\n",
        "    for i in range(len(serie)-lookback):\n",
        "        X.append(serie[i:i+lookback])\n",
        "        y.append(serie[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def antreneaza_lstm_univariabil(serie, lookback=30, epochs=20, batch_size=32, verbose=0):\n",
        "    scaler = MinMaxScaler()\n",
        "    s = scaler.fit_transform(serie.reshape(-1,1))\n",
        "    X, y = creeaza_secvente_univariabile(s.flatten(), lookback)\n",
        "    X = X.reshape((X.shape[0], lookback, 1))\n",
        "\n",
        "    split = int(len(X)*0.8)\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    model = Sequential([LSTM(50, input_shape=(lookback,1)), Dense(1)])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "    y_test_res = scaler.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "    y_pred_res = scaler.inverse_transform(y_pred.reshape(-1,1)).flatten()\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_res, y_pred_res))\n",
        "    r2 = r2_score(y_test_res, y_pred_res)\n",
        "    acc_dir = np.mean(np.sign(np.diff(y_test_res)) == np.sign(np.diff(y_pred_res)))\n",
        "    return {'y_test': y_test_res, 'y_pred': y_pred_res, 'RMSE': rmse, 'R2': r2, 'Acc_dir': acc_dir}\n",
        "\n",
        "# -------------------------\n",
        "# 9. LSTM multivariabil multi-horizon\n",
        "# -------------------------\n",
        "def antreneaza_lstm_multi_orizont(df, caracteristici, coloana_target='BTC_Close', lookback=30, epochs=30, batch_size=16, horizons=[1,5,7]):\n",
        "    scalerX = MinMaxScaler()\n",
        "    scalerY = MinMaxScaler()\n",
        "\n",
        "    X_all = scalerX.fit_transform(df[caracteristici])\n",
        "    Y_all = scalerY.fit_transform(df[[coloana_target]])\n",
        "\n",
        "    def creeaza_seq_multi(X,Y,lb,h):\n",
        "        Xs, Ys = [], []\n",
        "        for i in range(len(X)-lb-h+1):\n",
        "            Xs.append(X[i:i+lb])\n",
        "            Ys.append(Y[i+lb+h-1])\n",
        "        return np.array(Xs), np.array(Ys)\n",
        "\n",
        "    rezultate = {}\n",
        "    for h in horizons:\n",
        "        Xs, Ys = creeaza_seq_multi(X_all,Y_all,lookback,h)\n",
        "        split = int(len(Xs)*0.8)\n",
        "        X_train, X_test = Xs[:split], Xs[split:]\n",
        "        y_train, y_test = Ys[:split], Ys[split:]\n",
        "\n",
        "        model = Sequential([LSTM(64, input_shape=(lookback, X_train.shape[2])), Dropout(0.2), Dense(1)])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        y_pred_s = model.predict(X_test).flatten()\n",
        "        y_pred = scalerY.inverse_transform(y_pred_s.reshape(-1,1)).flatten()\n",
        "        y_real = scalerY.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(y_real, y_pred))\n",
        "        acc_dir = np.mean(np.sign(np.diff(y_real)) == np.sign(np.diff(y_pred)))\n",
        "        corr = np.corrcoef(y_real, y_pred)[0,1]\n",
        "\n",
        "        rezultate[h] = {'y_real': y_real, 'y_pred': y_pred, 'RMSE': rmse, 'Acc_dir': acc_dir, 'Pearson': corr}\n",
        "        print(f\"Orizont {h} zile: RMSE={rmse:.3f}, Acc_dir={acc_dir:.3f}, Pearson={corr:.3f}\")\n",
        "\n",
        "    return rezultate\n",
        "\n",
        "# -------------------------\n",
        "# 10. Plot multi-scenariu\n",
        "# -------------------------\n",
        "def plot_multi_scenariu_continuu(dates, preturi, predictii_dict):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(preturi[-100:], label='BTC real', color='black', alpha=0.5)\n",
        "\n",
        "    culori = {1:'blue',5:'green',7:'red'}\n",
        "    for h,v in predictii_dict.items():\n",
        "        y_pred = np.ravel(v['y_pred'])\n",
        "        last_val = float(np.ravel(preturi)[-1])\n",
        "        start_idx = len(preturi)-1\n",
        "        y_plot = np.concatenate(([last_val], y_pred))\n",
        "        x_plot = range(start_idx, start_idx+len(y_plot))\n",
        "        plt.plot(x_plot, y_plot, label=f'Predicție +{h} zile', color=culori.get(h,'C0'))\n",
        "\n",
        "    plt.title(\"Predicții BTC multi-scenariu (continuu)\")\n",
        "    plt.xlabel(\"Pași de timp\")\n",
        "    plt.ylabel(\"BTC Close (USD)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# PIPELINE PRINCIPAL\n",
        "# -------------------------\n",
        "def main(save_csv=SALVEAZA_CSV):\n",
        "    # 1. Descărcare date\n",
        "    df_raw = descarca_btc_si_macro(ANI)\n",
        "\n",
        "    # 2. Preprocesare\n",
        "    df = preproceseaza(df_raw)\n",
        "\n",
        "    # salvare opțională\n",
        "    if save_csv:\n",
        "        df.to_csv('btc_merged_clean.csv')\n",
        "        print('Salvat btc_merged_clean.csv')\n",
        "\n",
        "    # 3. Eliminare valori aberante\n",
        "    df_curat, masc_aberante = elimina_outlieri_iqr(df)\n",
        "    print(f\"Rânduri inițiale: {len(df)}, după eliminarea valorilor aberante: {len(df_curat)}\")\n",
        "\n",
        "    # 4. Adăugare caracteristici BTC (pe prețuri originale, nescalate)\n",
        "    df_feat = df.copy()\n",
        "    df_feat = adauga_caracteristici_btc(df_feat)\n",
        "\n",
        "    # 5. Pregătire seturi pentru modele clasice\n",
        "    coloane_numerice = df_feat.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    df_scaled = df_feat.copy()\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled[coloane_numerice] = scaler.fit_transform(df_feat[coloane_numerice])\n",
        "\n",
        "    # Dicționar seturi: complet vs curat\n",
        "    seturi = {'Complet': df_scaled.copy(), 'Curat': df_scaled.loc[~masc_aberante].copy()}\n",
        "\n",
        "    # 6. Split feature/target și stocare splituri\n",
        "    coloana_target = 'Bitcoin'\n",
        "    splituri = {}\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "    for nume, d in seturi.items():\n",
        "        coloane_feat = [c for c in d.columns if c != coloana_target]\n",
        "        X = d[coloane_feat]\n",
        "        y = d[coloana_target]\n",
        "        X_imp = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "        splituri[nume] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
        "\n",
        "    # 7. Evaluare modele clasice\n",
        "    rezultate_df = evalueaza_modele_clasice(splituri)\n",
        "    print('\\nRezumat modele clasice:')\n",
        "    display(rezultate_df.sort_values(['Set','R2'], ascending=[True, False]))\n",
        "\n",
        "    # 8. Analiză multi-target (folosim df_feat nescalat pentru interpretabilitate)\n",
        "    coloane_target = ['BTC_lag1','BTC_lag2','BTC_ma7','BTC_ma14','BTC_diff1','BTC_pct_change']\n",
        "    coloane_feat = [c for c in df_feat.columns if c not in coloane_target]\n",
        "\n",
        "    rez_multi_target = analiza_multi_target(df_feat, coloane_feat, coloane_target)\n",
        "    print('\\nRezumat multi-target:')\n",
        "    display(rez_multi_target)\n",
        "\n",
        "    # 9. LSTM univariabil baseline (exemplu pe BTC_diff1)\n",
        "    print('\\nBaseline LSTM univariabil pe BTC_diff1 (exemplu)')\n",
        "    if 'BTC_diff1' in df_feat.columns:\n",
        "        res_uni = antreneaza_lstm_univariabil(df_feat['BTC_diff1'].values, lookback=30, epochs=20)\n",
        "        print('Rezultate LSTM univariabil:', res_uni['RMSE'], res_uni['R2'], res_uni['Acc_dir'])\n",
        "\n",
        "    # 10. LSTM multivariabil multi-orizont (1 an BTC)\n",
        "    print('\\nPregătire date pentru LSTM multi-orizont (1 an)')\n",
        "    sfarsit = datetime.today()\n",
        "    start = sfarsit - timedelta(days=365)\n",
        "    btc_df = yf.download('BTC-USD', start=start, end=sfarsit, interval='1d', progress=False)[['Close']].rename(columns={'Close':'BTC_Close'})\n",
        "    btc_df = btc_df.reset_index()\n",
        "    btc_df['BTC_diff1'] = btc_df['BTC_Close'].diff()\n",
        "    btc_df['BTC_pct_change'] = btc_df['BTC_Close'].pct_change()\n",
        "    btc_df['BTC_ma7'] = btc_df['BTC_Close'].rolling(7).mean()\n",
        "    btc_df['BTC_ma14'] = btc_df['BTC_Close'].rolling(14).mean()\n",
        "    btc_df['BTC_vol'] = btc_df['BTC_diff1'].rolling(3).std()\n",
        "    btc_df = btc_df.dropna().reset_index(drop=True)\n",
        "\n",
        "    caracteristici = ['BTC_Close','BTC_ma7','BTC_ma14','BTC_diff1','BTC_pct_change','BTC_vol']\n",
        "    rez_lstm_multi = antreneaza_lstm_multi_orizont(\n",
        "    btc_df[caracteristici],\n",
        "    caracteristici,\n",
        "    coloana_target='BTC_Close',\n",
        "    lookback=30,\n",
        "    epochs=30,\n",
        "    horizons=[1,5,7]\n",
        "    )\n",
        "\n",
        "    # 11. Plot predicții continue ancorate pe ultima valoare reală\n",
        "    history_dates = btc_df['Date'].values[-100:]\n",
        "    history_prices = btc_df['BTC_Close'].values[-100:]\n",
        "    preds_plot = {h:{'y_pred':v['y_pred']} for h,v in rez_lstm_multi.items()}\n",
        "    plot_multi_scenariu_continuu(history_dates, history_prices, preds_plot)\n",
        "\n",
        "    # 12. Salvare rezultate și artefacte\n",
        "    asigura_folder('outputs')\n",
        "    if save_csv:\n",
        "        rezultate_df.to_csv('outputs/rezultate_modele_clasice.csv', index=False)\n",
        "        rez_multi_target.to_csv('outputs/rezumat_multi_target.csv', index=False)\n",
        "        pd.DataFrame([{ 'orizont':h, **{k:v for k,v in rez_lstm_multi[h].items() if k in ['RMSE','Acc_dir','Pearson']} } for h in rez_lstm_multi]).to_csv('outputs/lstm_multi_orizont.csv', index=False)\n",
        "        print('Rezultatele au fost salvate în folderul outputs/')\n",
        "\n",
        "    print('\\nPipeline finalizat.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "NCshhctJVSc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}